-- The input table (filled by the loader)
CREATE TABLE IF NOT EXISTS Domains_Input
(
    id            BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    domain        TEXT        NOT NULL UNIQUE,
    first_seen    TIMESTAMPTZ NOT NULL DEFAULT now(),
    last_seen     TIMESTAMPTZ NOT NULL,
    filter_output JSONB
);

-- User-specified input filters
CREATE TABLE IF NOT EXISTS Custom_Prefilter
(
    id                     INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    name                   TEXT        NOT NULL,
    description            TEXT,
    enabled                BOOLEAN              DEFAULT TRUE,
    action                 INT                  DEFAULT 0 CHECK (action >= 0 AND action <= 3),
    last_updated_timestamp TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE TABLE IF NOT EXISTS Custom_Prefiltered_Domain
(
    custom_prefilter_id INT  NOT NULL REFERENCES Custom_Prefilter (id) ON DELETE CASCADE,
    domain_name         TEXT NOT NULL,
    PRIMARY KEY (custom_prefilter_id, domain_name)
);

-- Enums
CREATE TABLE IF NOT EXISTS Collector
(
    id              SMALLINT PRIMARY KEY,
    collector       TEXT    NOT NULL UNIQUE,
    is_ip_collector BOOLEAN NOT NULL
);

CREATE TABLE IF NOT EXISTS Classification_Category
(
    id       SMALLINT PRIMARY KEY,
    category TEXT NOT NULL UNIQUE
);

CREATE TABLE IF NOT EXISTS Classifier_Type
(
    id          SMALLINT PRIMARY KEY,
    category_id SMALLINT REFERENCES Classification_Category (id),
    classifier  TEXT NOT NULL,
    UNIQUE (category_id, classifier)
);

CREATE TABLE IF NOT EXISTS Collector_Status_Type
(
    status_code SMALLINT PRIMARY KEY,
    name        TEXT NOT NULL,
    description TEXT NULL
);

DROP TABLE IF EXISTS Domain CASCADE;
DROP TABLE IF EXISTS Domain_Errors CASCADE;
DROP TABLE IF EXISTS IP CASCADE;
DROP TABLE IF EXISTS Classification_Category_Result CASCADE;
DROP TABLE IF EXISTS Classifier_Output CASCADE;
DROP TABLE IF EXISTS Collection_Result CASCADE;
DROP TABLE IF EXISTS QRadar_Offense_In_Source CASCADE;
DROP TABLE IF EXISTS QRadar_Offense_Source CASCADE;
DROP TABLE IF EXISTS QRadar_Offense CASCADE;
DROP TABLE IF EXISTS Feature_Vector CASCADE;
DROP TABLE IF EXISTS Collection_Results_Dummy_Target CASCADE;
DROP TABLE IF EXISTS Classification_Results_Dummy_Target CASCADE;

-- Domains
CREATE TABLE Domain
(
    id                    BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    domain_name           TEXT UNIQUE NOT NULL,
    aggregate_probability REAL        NULL,
    aggregate_description TEXT        NULL,
    last_update           TIMESTAMPTZ NOT NULL
);

CREATE TABLE Domain_Errors
(
    domain_id         BIGINT      NOT NULL REFERENCES Domain (id),
    discriminator     UUID        NOT NULL DEFAULT gen_random_uuid(),
    timestamp         TIMESTAMPTZ NOT NULL,
    source            TEXT        NOT NULL,
    error             TEXT        NOT NULL,
    sql_error_code    TEXT        NULL,
    sql_error_message TEXT        NULL,
    PRIMARY KEY (domain_id, discriminator)
);

-- IPs
CREATE TABLE IP
(
    id                       BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    domain_id                BIGINT           NOT NULL REFERENCES Domain (id),
    ip                       INET             NOT NULL,
    geo_country_code         TEXT             NULL,
    geo_region               TEXT             NULL,
    geo_region_code          TEXT             NULL,
    geo_city                 TEXT             NULL,
    geo_postal_code          TEXT             NULL,
    geo_latitude             DOUBLE PRECISION NULL,
    geo_longitude            DOUBLE PRECISION NULL,
    geo_timezone             TEXT             NULL,
    asn                      BIGINT           NULL,
    as_org                   TEXT             NULL,
    network_address          TEXT             NULL,
    network_prefix_length    INTEGER          NULL,
    nerd_reputation          DOUBLE PRECISION NULL,
    geo_asn_update_timestamp TIMESTAMPTZ      NULL,
    nerd_update_timestamp    TIMESTAMPTZ      NULL,
    UNIQUE (domain_id, ip)
);

-- Classification results
CREATE TABLE Classification_Category_Result
(
    id          BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    domain_id   BIGINT           NOT NULL REFERENCES Domain (id),
    timestamp   TIMESTAMPTZ      NOT NULL,
    category_id SMALLINT         NOT NULL REFERENCES Classification_Category (id),
    probability DOUBLE PRECISION NOT NULL,
    description TEXT             NULL,
    details     JSONB            NULL,
    CONSTRAINT Classification_Category_Result_Unique UNIQUE (domain_id, timestamp, category_id)
);

CREATE TABLE Classifier_Output
(
    result_id       BIGINT           NOT NULL REFERENCES Classification_Category_Result (id),
    classifier_id   SMALLINT         NOT NULL REFERENCES Classifier_Type (id),
    probability     DOUBLE PRECISION NOT NULL,
    additional_info TEXT             NULL,
    PRIMARY KEY (result_id, classifier_id)
);

-- Collection results
CREATE TABLE Collection_Result
(
    id          BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    domain_id   BIGINT      NOT NULL REFERENCES Domain (id),
    ip_id       BIGINT      NULL REFERENCES IP (id),
    source_id   SMALLINT    NOT NULL REFERENCES Collector (id),
    status_code SMALLINT    NOT NULL REFERENCES Collector_Status_Type (status_code),
    error       TEXT        NULL,
    timestamp   TIMESTAMPTZ NOT NULL,
    raw_data    JSONB       NULL,
    CONSTRAINT Collection_Result_Unique UNIQUE NULLS NOT DISTINCT (domain_id, ip_id, source_id, timestamp)
);

-- QRadar
CREATE TABLE QRadar_Offense_Source
(
    id               BIGINT PRIMARY KEY,
    ip               INET    NULL,
    qradar_domain_id INTEGER NOT NULL,
    magnitude        REAL    NOT NULL
);

CREATE TABLE QRadar_Offense
(
    id                BIGINT PRIMARY KEY,
    description       TEXT        NULL,
    event_count       INTEGER     NOT NULL DEFAULT 0,
    flow_count        INTEGER     NOT NULL DEFAULT 0,
    device_count      INTEGER     NOT NULL DEFAULT 0,
    severity          REAL        NOT NULL,
    magnitude         REAL        NOT NULL,
    last_updated_time TIMESTAMPTZ NOT NULL,
    status            TEXT        NULL
);

CREATE TABLE QRadar_Offense_In_Source
(
    offense_source_id BIGINT NOT NULL REFERENCES QRadar_Offense_Source (id) ON DELETE CASCADE,
    offense_id        BIGINT NOT NULL REFERENCES QRadar_Offense (id) ON DELETE CASCADE,
    PRIMARY KEY (offense_id, offense_source_id)
);

-- Feature vectors
CREATE TABLE Feature_Vector
(
    id          BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    domain_name TEXT  NOT NULL REFERENCES Domain (domain_name),
    data        JSONB NOT NULL
);

--- Indices ---

-- Enable trigram indices
CREATE EXTENSION IF NOT EXISTS pg_trgm;

-- Misc
CREATE INDEX ON Classifier_Type USING HASH (classifier);
CREATE INDEX ON Collector USING HASH (collector);
-- Joins IPs with QRadar data
CREATE INDEX ON QRadar_Offense_Source (ip);
-- Domain data lookups
CREATE INDEX ON Classification_Category_Result (domain_id DESC);
CREATE INDEX ON Classification_Category_Result (category_id);
CREATE INDEX ON Classification_Category_Result (probability DESC);
CREATE INDEX ON Classification_Category_Result (category_id, probability DESC);
-- Domain/IP data lookups
CREATE INDEX ON IP (domain_id DESC);
CREATE INDEX ON IP (ip DESC);
-- Collection result lookups
CREATE INDEX ON Collection_Result (domain_id);
CREATE INDEX ON Collection_Result (ip_id);
-- Sorting in the UI
CREATE INDEX ON Domain (aggregate_probability DESC);
CREATE INDEX ON Domain (last_update DESC);
CREATE INDEX domain_names_trigram_index ON Domain USING GIST (domain_name gist_trgm_ops(siglen=32));
-- Stats
CREATE INDEX ON Domains_Input (first_seen DESC);

--- Inserting data ---

-- A dummy target table for the collection results Kafka Connect sink
CREATE TABLE Collection_Results_Dummy_Target
(
    domain_name TEXT     NOT NULL,
    ip          TEXT     NULL,
    collector   TEXT     NOT NULL,
    status_code SMALLINT NOT NULL,
    error       TEXT     NULL,
    timestamp   BIGINT   NOT NULL, -- Unix time in ms
    raw_data    TEXT     NULL
);

-- CA dummy target table for the classification results Kafka Connect sink
CREATE TABLE Classification_Results_Dummy_Target
(
    domain_name TEXT NOT NULL,
    raw_data    TEXT NOT NULL
);

CREATE OR REPLACE FUNCTION insert_or_get_domain_and_ip(p_domain_name TEXT, p_ip TEXT, p_update_timestamp TIMESTAMPTZ,
                                                       OUT r_domain_id BIGINT, OUT r_ip_id BIGINT)
AS
$$
DECLARE
    v_new_ip INET;
BEGIN
    -- Insert or get domain
    INSERT INTO Domain (domain_name, last_update)
    VALUES (p_domain_name, p_update_timestamp)
    ON CONFLICT (domain_name) DO UPDATE
        SET last_update = p_update_timestamp
    RETURNING id INTO r_domain_id;

    -- Insert or get IP
    IF p_ip IS NOT NULL THEN
        v_new_ip := CAST(p_ip as INET);

        INSERT INTO IP (ip, domain_id)
        VALUES (v_new_ip, r_domain_id)
        ON CONFLICT (ip, domain_id) DO NOTHING;

        SELECT id INTO r_ip_id FROM IP WHERE domain_id = r_domain_id AND ip = v_new_ip;
    ELSE
        r_ip_id := NULL;
    END IF;

    RETURN;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION update_ip_data(
    p_ip_id BIGINT,
    p_collector_name TEXT,
    p_data JSONB,
    p_timestamp TIMESTAMPTZ,
    p_status_code INT
)
    RETURNS VOID
AS
$$
BEGIN
    IF p_ip_id IS NOT NULL AND p_data IS NOT NULL AND p_status_code = 0 THEN
        IF p_collector_name = 'geo-asn' THEN
            p_data := p_data -> 'data';
            IF p_data IS NULL OR jsonb_typeof(p_data) != 'object' THEN
                RETURN;
            END IF;

            UPDATE IP
            SET geo_country_code         = p_data ->> 'countryCode',
                geo_region               = p_data ->> 'region',
                geo_region_code          = p_data ->> 'regionCode',
                geo_city                 = p_data ->> 'city',
                geo_postal_code          = p_data ->> 'postalCode',
                geo_latitude             = NULLIF(p_data -> 'latitude', 'null'::jsonb)::DOUBLE PRECISION,
                geo_longitude            = NULLIF(p_data -> 'longitude', 'null'::jsonb)::DOUBLE PRECISION,
                geo_timezone             = p_data ->> 'timezone',
                asn                      = NULLIF(p_data -> 'asn', 'null'::jsonb)::BIGINT,
                as_org                   = p_data ->> 'asnOrg',
                network_address          = p_data ->> 'networkAddress',
                network_prefix_length    = NULLIF(p_data -> 'prefixLength', 'null'::jsonb)::INTEGER,
                geo_asn_update_timestamp = p_timestamp
            WHERE id = p_ip_id
              AND (geo_asn_update_timestamp IS NULL OR geo_asn_update_timestamp <= p_timestamp);
        ELSIF p_collector_name = 'nerd' THEN
            UPDATE IP
            SET nerd_reputation       = NULLIF(p_data -> 'data' -> 'reputation', 'null'::jsonb)::DOUBLE PRECISION,
                nerd_update_timestamp = p_timestamp
            WHERE id = p_ip_id
              AND (nerd_update_timestamp IS NULL OR nerd_update_timestamp <= p_timestamp);
        END IF;
    END IF;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION insert_collection_result()
    RETURNS trigger AS
$$
DECLARE
    v_domain_id         BIGINT;
    v_ip_id             BIGINT;
    v_collector_id      SMALLINT;
    v_collector_for_ip  BOOLEAN;
    -- v_new_record        Collection_Result_Referenced%ROWTYPE;
    v_timestamp         TIMESTAMPTZ;
    v_deserialized_data JSONB;
BEGIN
    -- Convert the input Unix timestamp to TIMESTAMPTZ
    v_timestamp := (timestamptz 'epoch' + (NEW.timestamp * interval '1 millisecond'));

    -- Insert or get domain and IP
    SELECT r_domain_id, r_ip_id
    INTO v_domain_id, v_ip_id
    FROM insert_or_get_domain_and_ip(NEW.domain_name, NEW.ip, v_timestamp);

    -- Deserialize the input JSON, handle errors
    BEGIN
        v_deserialized_data := NEW.raw_data::JSONB;
    EXCEPTION
        WHEN OTHERS THEN
            INSERT INTO Domain_Errors (domain_id, timestamp, source, error, sql_error_code, sql_error_message)
            VALUES (v_domain_id, v_timestamp, 'insert_collection_result',
                    'Cannot parse JSON.', SQLSTATE, SQLERRM);

            v_deserialized_data := NULL;
    END;

    -- Check collector
    SELECT id, is_ip_collector INTO v_collector_id, v_collector_for_ip FROM Collector WHERE collector = NEW.collector;
    IF v_collector_id IS NULL THEN
        INSERT INTO Domain_Errors (domain_id, timestamp, source, error, sql_error_code, sql_error_message)
        VALUES (v_domain_id, v_timestamp, 'insert_collection_result',
                'Unknown collector ID: ' || NEW.collector);
        RETURN NULL;
    END IF;

    -- Update IP data
    IF v_ip_id IS NOT NULL AND v_deserialized_data IS NOT NULL THEN
        PERFORM update_ip_data(v_ip_id,
                               NEW.collector,
                               v_deserialized_data,
                               v_timestamp,
                               NEW.status_code);
    END IF;

    -- Insert into Collection_Result
    -- IMPORTANT: Change the two occurrences of 'v_deserialized_data' to 'NULL' to disable storing raw data
    
    -- $$$
    INSERT INTO Collection_Result (domain_id, ip_id, source_id, status_code, error, timestamp, raw_data)
    VALUES (v_domain_id, v_ip_id, v_collector_id, NEW.status_code, NEW.error,
            v_timestamp, v_deserialized_data)
    ON CONFLICT ON CONSTRAINT collection_result_unique DO UPDATE
        SET status_code = NEW.status_code,
            error       = NEW.error,
            raw_data    = v_deserialized_data;
    -- $$$

    -- Don't save the record in the original table
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION insert_classification_result()
    RETURNS trigger AS
$$
DECLARE
    v_domain_id              BIGINT;
    v_deserialized_data      JSONB;
    v_aggregate_prob         DOUBLE PRECISION;
    v_aggregate_desc         TEXT;
    v_timestamp              TIMESTAMPTZ;
    v_classification_results JSONB;
    v_classification_result  JSONB;
    v_category               SMALLINT;
    v_probability            DOUBLE PRECISION;
    v_description            TEXT;
    v_details                JSONB;
    v_result_id              BIGINT;
    v_detail_rec             RECORD;
    v_error                  TEXT;
    v_sql_error_code         TEXT;
    v_sql_error_message      TEXT;
BEGIN
    BEGIN
        v_sql_error_code := NULL;
        v_sql_error_message := NULL;

        -- Deserialize the input JSON
        v_deserialized_data := NEW.raw_data::JSONB;

        -- Get top-level fields
        v_aggregate_prob := COALESCE((v_deserialized_data ->> 'aggregate_probability')::DOUBLE PRECISION, -1.0);
        v_aggregate_desc := (v_deserialized_data ->> 'aggregate_description');
        v_error := (v_deserialized_data ->> 'error');
        v_timestamp := COALESCE(
                (timestamptz 'epoch' + (((v_deserialized_data ->> 'timestamp')::BIGINT) * interval '1 millisecond')),
                now());
    EXCEPTION
        WHEN OTHERS THEN
            v_aggregate_prob := -1;
            v_aggregate_desc := NULL;
            v_error := 'Cannot parse JSON.';
            v_timestamp := now();
            v_sql_error_code := SQLSTATE;
            v_sql_error_message := SQLERRM;
    END;

    -- Insert or get domain
    INSERT INTO Domain (domain_name, aggregate_probability, aggregate_description, last_update)
    VALUES (NEW.domain_name, v_aggregate_prob,
            v_aggregate_desc, v_timestamp)
    ON CONFLICT (domain_name)
        DO UPDATE
        SET aggregate_probability = v_aggregate_prob,
            aggregate_description = v_aggregate_desc,
            last_update           = v_timestamp
    RETURNING id INTO v_domain_id;

    -- If an error occurred, no results will be present
    IF v_error IS NOT NULL THEN
        INSERT INTO Domain_Errors (domain_id, timestamp, source, error, sql_error_code, sql_error_message)
        VALUES (v_domain_id, v_timestamp, 'insert_classification_result',
                v_error, v_sql_error_code, v_sql_error_message);
        RETURN NULL;
    END IF;

    -- Get the classification_results array from the input JSON
    v_classification_results := v_deserialized_data -> 'classification_results';
    IF v_classification_results IS NULL OR jsonb_typeof(v_classification_result) != 'array' THEN
        INSERT INTO Domain_Errors (domain_id, timestamp, source, error)
        VALUES (v_domain_id, v_timestamp, 'insert_classification_result',
                'No classification results in the input data.');
        RETURN NULL;
    END IF;

    -- Loop through each classification_result in the array
    FOR v_classification_result IN SELECT value FROM jsonb_array_elements(v_classification_results) AS t(value)
        LOOP
            BEGIN
                -- Extract fields from the classification_result JSON object
                v_category := (v_classification_result ->> 'category')::SMALLINT;
                v_probability := (v_classification_result ->> 'probability')::DOUBLE PRECISION;
                v_description := v_classification_result ->> 'description';
                v_details := v_classification_result -> 'details';

                -- Insert into Classification_Category_Result, handle conflict if entry exists
                INSERT INTO Classification_Category_Result (domain_id, timestamp, category_id, probability, description, details)
                VALUES (v_domain_id, v_timestamp, v_category, v_probability, v_description, NULL)
                ON CONFLICT ON CONSTRAINT classification_category_result_unique DO UPDATE
                    SET probability = EXCLUDED.probability,
                        description = EXCLUDED.description,
                        details     = EXCLUDED.details
                RETURNING id INTO v_result_id;

                -- If no details
                IF v_details IS NULL OR jsonb_typeof(v_details) != 'object' THEN
                    CONTINUE;
                END IF;

                -- Loop through each key-value pair in the details JSON object
                FOR v_detail_rec IN SELECT key, value FROM jsonb_each(v_details)
                    LOOP
                        -- Insert into Classifier_Output, handle conflict if entry exists
                        INSERT INTO Classifier_Output (result_id, classifier_id, probability, additional_info)
                        VALUES (v_result_id,
                                v_detail_rec.key::SMALLINT,
                                v_detail_rec.value::DOUBLE PRECISION,
                                NULL)
                        ON CONFLICT (result_id, classifier_id) DO UPDATE
                            SET probability     = EXCLUDED.probability,
                                additional_info = EXCLUDED.additional_info;
                    END LOOP;

            EXCEPTION
                WHEN OTHERS THEN
                    INSERT INTO Domain_Errors (domain_id, timestamp, source, error, sql_error_code, sql_error_message)
                    VALUES (v_domain_id, v_timestamp, 'insert_classification_result_loop',
                            'Cannot process classification result.', SQLSTATE, SQLERRM);
                    RETURN NULL;
            END;
        END LOOP;

    -- Don't save the record in the original table
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION pre_insert_feature_vector()
    RETURNS trigger AS
$$
BEGIN
    PERFORM insert_or_get_domain_and_ip(NEW.domain_name, NULL, now());
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE TRIGGER insert_collection_result_trigger
    BEFORE INSERT
    ON Collection_Results_Dummy_Target
    FOR EACH ROW
EXECUTE FUNCTION insert_collection_result();

CREATE OR REPLACE TRIGGER insert_classification_result_trigger
    BEFORE INSERT
    ON Classification_Results_Dummy_Target
    FOR EACH ROW
EXECUTE FUNCTION insert_classification_result();

CREATE OR REPLACE TRIGGER insert_feature_vector_trigger
    BEFORE INSERT
    ON Feature_Vector
    FOR EACH ROW
EXECUTE FUNCTION pre_insert_feature_vector();
